{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shapi88/tensorflow_book/blob/main/ml_resources.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE_7aYzB6q79"
      },
      "source": [
        "# ðŸ“– Resources\n",
        "\n",
        "### Documentation & APIs\n",
        "* ðŸ“– [Matrix Multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n",
        "* ðŸ“– [NumPy](https://numpy.org/doc/stable/reference/index.html)\n",
        "* ðŸ“– [Tensorflow](https://www.tensorflow.org/api_docs/python/tf)\n",
        "* ðŸ“– [Tensorflow Decision Forest](https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/all_symbols)\n",
        "* ðŸ“– [Pandas](https://pandas.pydata.org/docs/reference/index.html#api)\n",
        "* ðŸ“– [Seaborn](https://seaborn.pydata.org/)\n",
        "* ðŸ“– [Matplotlib](https://matplotlib.org/stable/plot_types/index.html)\n",
        "* ðŸ“– [Scipy](https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api)\n",
        "* ðŸ“– [Scikit Learn](https://scikit-learn.org/stable/)\n",
        "* ðŸ“– [Missingno](https://github.com/ResidentMario/missingno)\n",
        "* ðŸ“– [Daniel Bourke](https://www.mrdbourke.com)\n",
        "* ðŸ“– [Cheat Sheet Activation Function](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)\n",
        "\n",
        "### Videos\n",
        "* ðŸŽ¥ [10 crazy announcements from Google I/O - Fireship](https://www.youtube.com/watch?v=nmfRDRNjCnM)\n",
        "* ðŸŽ¥ [Daniel Bourke YT Channel](https://www.youtube.com/channel/UCr8O8l5cCX85Oem1d18EezQ)\n",
        "\n",
        "### Learning\n",
        "* ðŸ“– [kaggle](https://www.kaggle.com/)\n",
        "* ðŸ“– [ztm](https://zerotomastery.io/)\n",
        "\n",
        "### Tools\n",
        "* ðŸ›  [Matrix Multiplication calculator](http://matrixmultiplication.xyz/)\n",
        "* ðŸ›  [Google Collab](https://colab.research.google.com/)\n",
        "* ðŸ›  [ChatGPT](https://chat.openai.com/)\n",
        "* ðŸ›  [TF Playground](https://playground.tensorflow.org/)\n",
        "* ðŸ›  [NN Case Study](https://cs231n.github.io/neural-networks-case-study/)\n",
        "* ðŸ›  [Multi Layer Perceptron](https://github.com/GokuMohandas/Made-With-ML/blob/main/notebooks/08_Neural_Networks.ipynb)\n",
        "\n",
        "### Dojo\n",
        "\n",
        "* ðŸ¥‹ [mrdbourke/tensorflow-deep-learning Exercises](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/README.md#-02-neural-network-classification-with-tensorflow-exercises)\n",
        "\n",
        "### Twitters\n",
        "\n",
        "* ðŸªº [@ylecun, Researcher in AI, Machine Learning, Robotics](https://twitter.com/ylecun)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ¥µ TO-DO\n",
        "\n",
        "Check those:\n",
        "* ðŸ›  NN Case Study\n",
        "* ðŸ›  Multi Layer Perceptron\n",
        "* ðŸ›  Activation Functions Formulas"
      ],
      "metadata": {
        "id": "76cpuSIxyCMU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4kfHyDLkFX"
      },
      "source": [
        "# ðŸ’¡ Hyperparameters\n",
        "* Hyperparameters are parameters that are set before training a model and determine how the model is trained. These are not learned during training, but are specified by the user before training begins.\n",
        "\n",
        "* Hyperparameters are used to control aspects of the model's behavior, such as the learning rate, regularization strength, number of hidden layers, and number of nodes in each layer of a neural network. The choice of hyperparameters can have a significant impact on the model's performance, and finding the optimal values for them can be a challenging task that requires experimentation and tuning.\n",
        "\n",
        "* Hyperparameter tuning is the process of finding the best values for these parameters by adjusting them and training the model repeatedly, evaluating its performance each time. The goal is to find the hyperparameter values that result in the best performing model on a given task, such as classification or regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnGhZDmz1Dv8"
      },
      "source": [
        "# ðŸ”‘ Models\n",
        "There are many different types of machine learning models that exist, each with its own strengths and weaknesses. Here are some common types of machine learning models:\n",
        "\n",
        "* **Linear Regression**: A type of model used for predicting a continuous output value based on one or more input features.\n",
        "\n",
        "* **Logistic Regression**: A type of model used for binary classification problems, where the output variable takes one of two possible values.\n",
        "\n",
        "* **Decision Trees**: A type of model that makes decisions by recursively splitting the data based on the values of the input features.\n",
        "\n",
        "* **Random Forests**: An ensemble model that combines multiple decision trees to make predictions.\n",
        "\n",
        "* **Support Vector Machines (SVM)**: A model that finds the best hyperplane to separate the data into different classes.\n",
        "\n",
        "* **Naive Bayes**: A model that calculates the probability of each class based on the input features using Bayes' theorem.\n",
        "\n",
        "* **Neural Networks**: A type of model that consists of interconnected nodes that process information and can learn complex patterns in the data.\n",
        "\n",
        "* **Clustering Models**: A type of model used to group similar data points together based on their similarity.\n",
        "\n",
        "* **Dimensionality Reduction Models**: A type of model used to reduce the number of input features to a more manageable number.\n",
        "\n",
        "* **Reinforcement Learning Models**: A type of model used to learn from experience through a process of trial and error to maximize a reward signal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvU5wrZL2JKi"
      },
      "source": [
        "## Linear Regression Model\n",
        "\n",
        "This model uses TensorFlow's Keras API to create a sequential model with a single dense layer. The `units` argument specifies the number of neurons in the layer, and the `input_shape` argument specifies the shape of the input data.\n",
        "\n",
        "The model is compiled with stochastic gradient descent (SGD) as the optimizer and mean squared error (MSE) as the loss function. The model is then trained on the training data (`x_train` and `y_train`) for 100 epochs.\n",
        "\n",
        "Finally, the model is used to make a prediction on new data (`x_test`), and the predicted output is printed to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t9yeyhK1DKP",
        "outputId": "02dc00a3-f891-48b3-a371-7dec4a4a03c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[13.381614]], dtype=float32)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the input and output variables\n",
        "x_train = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
        "y_train = [3.0, 5.0, 7.0, 9.0, 11.0]\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.optimizers.SGD(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=100, verbose=0)\n",
        "\n",
        "# Make a prediction\n",
        "x_test = [6.0]\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6FvXYDl4rqL"
      },
      "source": [
        "## Logistic Regression Model\n",
        "\n",
        "We have a dataset with two features and binary classification labels. We define a logistic regression model using the `tf.keras.Sequential()` API, with a single `Dense` layer with one output unit and a sigmoid activation function.\n",
        "\n",
        "The model is compiled using stochastic gradient descent (`SGD`) as the optimizer and binary cross-entropy as the loss function. We then train the model on the training data using the `fit()` method.\n",
        "\n",
        "Finally, we use the trained model to make predictions on new data (`X_test`), and the predicted output is printed to the console."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnnGf2qg421O",
        "outputId": "5bdeb782-dff3-4f01-c5f3-d311c59d8f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "[[0.9735141]\n",
            " [0.9887447]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
        "y_train = np.array([0, 0, 1, 1, 1])\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(1, input_dim=2, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=1000, verbose=0)\n",
        "\n",
        "# Use the model to make predictions\n",
        "X_test = np.array([[6, 7], [7, 8]])\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOMES7bQ6E2m"
      },
      "source": [
        "## Decision Trees Model\n",
        "In this example, we're using the Iris dataset and creating a decision tree model using a neural network. We define the model using the `Sequential` API and add two fully connected layers with `Dense`. The first layer has 16 units and `ReLU` activation, while the second layer has 3 units and `softmax` activation, which is suitable for multiclass classification.\n",
        "\n",
        "The model is then compiled with the `adam` optimizer and `sparse_categorical_crossentropy` as the loss function. We then train the model on the entire dataset for 100 epochs.\n",
        "\n",
        "Finally, we evaluate the model on the same dataset and print out the test loss and accuracy. Note that in practice, it is usually better to split the data into separate training and testing sets to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hgd7hfU6Ia1",
        "outputId": "238a4407-3d0c-4632-aaa3-a3b29a0a7230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.9200\n",
            "Test loss: 0.42342260479927063, Test accuracy: 0.9200000166893005\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "  tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=100, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X, y)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYMxrmsb6jAG"
      },
      "source": [
        "## Random Forests Model\n",
        "\n",
        "In this example, we're using the Iris dataset and creating a Random Forest model using scikit-learn's `RandomForestClassifier`. We set the number of trees to be 100 by setting `n_estimators=100`.\n",
        "\n",
        "We then train the model on the entire dataset using the `fit` method.\n",
        "\n",
        "Finally, we evaluate the model on the same dataset using the `score` method, which returns the mean accuracy on the given data and labels. Note that in practice, it is usually better to split the data into separate training and testing sets to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7b33rjU6juK",
        "outputId": "bc1f17c9-8faa-401a-fa0e-b292ccf7e8ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Create a Random Forest model\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.score(X, y)\n",
        "print(f\"Test accuracy: {score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgH6bwnb7Dlq"
      },
      "source": [
        "## Support Vector Machines (SVM) Model\n",
        "\n",
        "In this example, we're using the Iris dataset and creating a SVM model using scikit-learn's `SVC`. We set the kernel to be linear by setting `kernel='linear'` and the regularization parameter `C` to be 1 by setting `C=1`.\n",
        "\n",
        "We then train the model on the entire dataset using the `fit` method.\n",
        "\n",
        "Finally, we evaluate the model on the same dataset using the `score` method, which returns the mean accuracy on the given data and labels. Note that in practice, it is usually better to split the data into separate training and testing sets to avoid overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IBKCF207qO3",
        "outputId": "ce74532a-3243-49b9-d147-44b417ae015d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9933333333333333\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Create a SVM model\n",
        "model = SVC(kernel='linear', C=1)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.score(X, y)\n",
        "print(f\"Test accuracy: {score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJtOUDvV7t_e"
      },
      "source": [
        "## Neural Networks Model\n",
        "\n",
        "In this example, we're using the Iris dataset and creating a Neural Network model using TensorFlow's Keras API. We're using a sequential model with two dense layers - the first with 64 units and a ReLU activation function, and the second with 3 units and a softmax activation function to output the predicted class probabilities.\n",
        "\n",
        "We compile the model with the 'adam' optimizer, the 'sparse_categorical_crossentropy' loss function (since our labels are integers), and the 'accuracy' metric to monitor during training.\n",
        "\n",
        "We then train the model on the training data for 100 epochs, using the validation set to monitor the model's performance during training.\n",
        "\n",
        "Finally, we evaluate the model on the test set using the `evaluate` method, which returns the loss and accuracy of the model on the given test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lxWbq4eL7tb1",
        "outputId": "caf5ed61-8446-4a5b-9071-f1349403f24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.0\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOnnx+0dAQ+hbm67B21yN46",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}